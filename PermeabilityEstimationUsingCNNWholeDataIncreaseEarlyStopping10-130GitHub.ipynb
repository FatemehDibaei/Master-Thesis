{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is a modified version of a code for building a 2D CNN model used for porosity estimation. \n",
    "The original code was made by Kurdistan Chawshin,  chawshinkurdistan@gmail.com, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImages = np.load('../WholeData/WholeDataTrainImage.npy')\n",
    "print(aaaiTrainImages.shape)\n",
    "\n",
    "aaaiTestImages = np.load('../WholeData/WholeDataTestImage.npy')\n",
    "print(aaaiTestImages.shape)\n",
    "\n",
    "afTrainPermeability = np.load('../WholeData/WholeDataTrainPermeability.npy')\n",
    "print(afTrainPermeability .shape)\n",
    "\n",
    "afTestPermeability  = np.load('../WholeData/WholeDataTestPermeability.npy')\n",
    "\n",
    "print(afTestPermeability .shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and validation sets split. 20% of the training set is used as the validation set. The validation set is used to evaluate the performance of the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImages, aaaiValidationImages, afTrainPermeability, afValidationPermeability  = train_test_split(aaaiTrainImages, afTrainPermeability , test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: \n",
    "We rotate train images by three angles of 90, 180, and 270 degress. These rotated images together with the original images will be used for training. Note that these images are also flipped horizontally on the fly using \"ImageDataGenerator\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImagesRot90 = np.rot90(aaaiTrainImages, axes=(1,2))\n",
    "\n",
    "afTrainPermeability 90 = np.copy(afTrainPermeability)\n",
    "aaaiTrainImagesRot180 = np.rot90(aaaiTrainImagesRot90, axes=(1,2))\n",
    "afTrainPermeability180 = np.copy(afTrainPermeability)\n",
    "aaaiTrainImagesRot270 = np.rot90(aaaiTrainImagesRot180, axes=(1,2))\n",
    "afTrainPermeability270 = np.copy(afTrainPermeability)\n",
    "\n",
    "aaaiTrainImages = np.concatenate((aaaiTrainImages, aaaiTrainImagesRot90, aaaiTrainImagesRot180, aaaiTrainImagesRot270), axis=0)\n",
    "afTrainPermeability = np.concatenate((afTrainPermeability, afTrainPermeability90, afTrainPermeability180, afTrainPermeability270), axis=0)\n",
    "\n",
    "print(aaaiTrainImages.shape)\n",
    "print(afTrainPermeability.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size and number of epochs for Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs =30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert each 64 x 64 image of the train and test set into a matrix of size 64 x 64 x 1 which is fed into the network. 1 is for number of channels. We are working with grayscale images. Therefore we have 1 channel. RGB images have 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPix, YPix = aaaiTrainImages.shape[1], aaaiTrainImages.shape[2]\n",
    "aaaiTrainImages = aaaiTrainImages.reshape(-1,XPix,YPix,1)\n",
    "aaaiValidationImages = aaaiValidationImages.reshape(-1,XPix,YPix,1)\n",
    "aaaiTestImages = aaaiTestImages.reshape(-1,XPix,YPix,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print image shape for train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Train Images shape with channel:', aaaiTrainImages.shape)\n",
    "print ('Validation Images shape with channel:', aaaiValidationImages.shape)\n",
    "print ('Test Images shape with channel:', aaaiTestImages.shape)\n",
    "print ('Train Permeability shape:', afTrainPermeability.shape)\n",
    "print ('Validation Permeability shape:', afValidationPermeability.shape)\n",
    "print ('Test Permeability shape:', afTestPermeability.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmenntation. Here we apply horizontal flip on the images that were already rotated by three degrees. We did the rotation outside Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataGen = ImageDataGenerator(rescale= 1/255., horizontal_flip=True)\n",
    "TrainDataGen.fit(aaaiTrainImages, augment=True)\n",
    "TrainGenerator = TrainDataGen.flow(aaaiTrainImages, afTrainPermeability, batch_size=batch_size, seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiValidationImages = aaaiValidationImages/255.\n",
    "aaaiTestImages = aaaiTestImages/255.\n",
    "print(np.min(aaaiTrainImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model structure. Here we perform hyperparameter tuning useing Keras Tuner library. \n",
    "A range of values are defined for each of the considered hyperparameters. The algorithm will\n",
    "consider different combinations and return the best configuration as the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreation(hp):\n",
    "    Regressor = keras.Sequential()\n",
    "    \n",
    "    Regressor.add(keras.layers.Conv2D(\n",
    "            filters= hp.Int('ConvFiltersInputLayer', min_value = 16, max_value=256,step=32),\n",
    "            kernel_size=hp.Choice('Conv2Kernel', values=[3,5]), padding='same',input_shape =(XPix, YPix, 1)))\n",
    "\n",
    "    Regressor.add(keras.layers.ReLU())\n",
    "    Regressor.add(keras.layers.MaxPooling2D(\n",
    "            pool_size=(2, 2),padding='same'))\n",
    "    \n",
    "    for i in range(hp.Int('ConvBlocks', 1, 3, default=1)):\n",
    "        Regressor.add(keras.layers.Conv2D(\n",
    "            filters= hp.Int(f'Conv{i}_Filter', min_value = 16, max_value=256, step=32),\n",
    "            kernel_size= hp.Choice('Conv2Kernel', values=[3,5]), padding='same'))\n",
    "    \n",
    "        Regressor.add(keras.layers.ReLU())\n",
    "        Regressor.add(keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "        \n",
    "    Regressor.add(keras.layers.Flatten())\n",
    "        \n",
    "    Regressor.add(keras.layers.Dense(\n",
    "            units= hp.Int('HiddenNeurons', 32, 256, step=32),\n",
    "            activation='linear'))\n",
    "    Regressor.add(keras.layers.ReLU())\n",
    "    \n",
    "    Regressor.add(keras.layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.6,default=0.00,step=0.2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    Regressor.add(keras.layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    #Compile the model\n",
    "    Regressor.compile(loss=\"mean_absolute_error\", optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('LearningRate',[1e-2, 1e-3, 1e-4])))\n",
    "    return Regressor\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = EarlyStopping(monitor='val_loss', mode='min', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperband using keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuner = Hyperband(ModelCreation, objective= 'val_loss', max_epochs =epochs, executions_per_trial =1, seed=seed, directory=os.path.normpath('../codeOutputs/Permeability/TransportProp'), project_name='HyperUnRotValWholeDataMAEEarlyStopping10')\n",
    "\n",
    "Tuner.search(TrainGenerator, verbose=2, validation_data= (aaaiValidationImages, afValidationPermeability), epochs=epochs, callbacks=[EarlyStop])\n",
    "\n",
    "Tuner.search_space_summary()\n",
    "\n",
    "Model = Tuner.get_best_models(1)[0]\n",
    "\n",
    "print(Model.summary())\n",
    "\n",
    "Tuner.results_summary()\n",
    "\n",
    "print(Tuner.get_best_hyperparameters(1)[0].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best returned model will train for more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 300\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', mode='min', patience=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"../CheckPointTest/TwoDArchitectureAugmentation/\"\n",
    "\n",
    "ckpt_pathname = experiment + \"/cp-{epoch:04d}.ckpt\"\n",
    "csv_filename = experiment + \"/metricsTwoDArchitectureAugmentation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback that saves the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_pathname, verbose=1)\n",
    "metrics_callback = tf.keras.callbacks.CSVLogger(csv_filename, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRegressor = Model.fit(TrainGenerator, validation_data = (aaaiValidationImages, afValidationPermeability), epochs=Epochs, callbacks =[EarlyStop], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the specified checkpoint you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model = keras.models.load_model(experiment + \"cp-0005.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits the model after loading the ckechpoints an initial epoch you want to start with (eg:stopped after epoch 10, but initial epoch at 10, because it starts couting from 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BestRegressor1 = Model.fit(aaaiTrainImages, afTrainPermeability , validation_data = (aaaiValidationImages, afValidationPermeability), epochs=Epochs, initial_epoch=5, callbacks =[EarlyStop, cp_callback,metrics_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "print('Training took: ',(t1 - t0)/60,'minutes')\n",
    "TestLoss  = Model.evaluate(aaaiTestImages, afTestPermeability, verbose=2)\n",
    "print('Test loss:', TestLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the improvement in loss function for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(BestRegressor.history['loss'], color ='b')\n",
    "plt.plot(BestRegressor.history['val_loss'], color = 'r')\n",
    "#plt.title('model loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig('EpocsVsMSEWholeDataEarlystopping.png',dpi=1200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and save the model and predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afPredictedPermeability = Model.predict(aaaiTestImages)\n",
    "np.savetxt('../codeOutputs/Permeability/TransportProp/PredictedPermeability300EpochsMAEMoreConvUnrotatedValidationWholeDataMAEEarlyStopping10.csv', afPredicted)\n",
    "save_model(Model, filepath= '../Models/PermeabilityEstimation/CNNModelForPermeabilityEstimation300EpochsMAEMoreConUnrotatedValidationWholeDataMAEEarlyStopping10', include_optimizer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
