{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is a modified version of a code for building a 3D CNN model used for lithology classification. \n",
    "The original code was made by Kurdistan Chawshin,  chawshinkurdistan@gmail.com, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "import os \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImages = np.load('../3DFixed/TrainImageSlicesFor3DPermeabilityEstimationFixed.npy')\n",
    "print(aaaiTrainImages.shape)\n",
    "\n",
    "aaaiTestImages = np.load('../3DFixed/TestImageSlicesFor3DPermeabilityEstimationFixed.npy')\n",
    "print(aaaiTestImages.shape)\n",
    "\n",
    "aaaiValidationImages= np.load('../3DFixed/ValidationImageSlicesFor3DPermeabilityEstimationFixed.npy')\n",
    "print(aaaiValidationImages.shape)\n",
    "\n",
    "afTrainPermeability = np.load('../3DFixed/TrainPermeabilityFor3DPermeabilityEstimationFixed.npy')\n",
    "afTrainPermeability  = np.log(afTrainPermeability )\n",
    "print(afTrainPermeability.shape)\n",
    "\n",
    "afTestPermeability  = np.load('../3DFixed/TestPermeabilityFor3DPermeabilityEstimationFixed.npy')\n",
    "afTestPermeability  = np.log(afTestPermeability )\n",
    "print(afTestPermeability.shape)\n",
    "\n",
    "afValidationPermeability  = np.load('../3DFixed/ValidationPermeabilityFor3DPermeabilityEstimationFixed.npy')\n",
    "afValidationPermeability  = np.log(afValidationPermeability )\n",
    "print(afValidationPermeability.shape)\n",
    "\n",
    "print(afValidationPermeability [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size and number of epochs for Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert each 19 x 19 x 19 image of the train, validation and test set into a matrix of size 19 x 19 x 19 1 which is fed into the network. 1 is for number of channels. We are working with grayscale images. Therefore we have 1 channel. RGB images have 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPix, YPix,ZPix = aaaiTrainImages.shape[1], aaaiTrainImages.shape[2],aaaiTrainImages.shape[3]\n",
    "aaaiTrainImages = aaaiTrainImages.reshape(-1,XPix,YPix,ZPix,1)\n",
    "aaaiValidationImages = aaaiValidationImages.reshape(-1,XPix,YPix,ZPix,1)\n",
    "aaaiTestImages = aaaiTestImages.reshape(-1,XPix,YPix,ZPix,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print image shape for train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Train Images shape with channel:', aaaiTrainImages.shape)\n",
    "print ('Validation Images shape with channel:', aaaiValidationImages.shape)\n",
    "print ('Test Images shape with channel:', aaaiTestImages.shape)\n",
    "print ('Train permeability shape:', afTrainPermeability .shape)\n",
    "print ('Validation Permeability shape:', afValidationPermeability .shape)\n",
    "print ('Test Permeability  shape:', afTestPermeability .shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImages = aaaiTrainImages/255. \n",
    "aaaiValidationImages = aaaiValidationImages/255.\n",
    "aaaiTestImages = aaaiTestImages/255.\n",
    "print(np.min(aaaiTrainImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, ReLU, GlobalAveragePooling3D\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model structure. Here we perform hyperparameter tuning useing Keras Tuner library. \n",
    "A range of values are defined for each of the considered hyperparameters. The algorithm will\n",
    "consider different combinations and return the best configuration as the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreation(hp):\n",
    "    Regressor = keras.Sequential()\n",
    "    \n",
    "    Regressor.add(keras.layers.Conv3D(\n",
    "            filters= hp.Int('ConvFiltersInputLayer', min_value = 16, max_value=256,step=32),\n",
    "            kernel_size=hp.Choice('Conv2Kernel', values=[3,5]), padding='same',input_shape =(XPix, YPix,ZPix,1)))\n",
    "\n",
    "    Regressor.add(keras.layers.ReLU())\n",
    "    Regressor.add(keras.layers.MaxPooling3D(\n",
    "            pool_size=(2,2,2),padding='same'))\n",
    "    \n",
    "    for i in range(hp.Int('ConvBlocks', 1, 2, default=1)): \n",
    "        Regressor.add(keras.layers.Conv3D(\n",
    "            filters= hp.Int(f'Conv{i}_Filter', min_value = 16, max_value=256, step=32),\n",
    "            kernel_size= hp.Choice('Conv2Kernel', values=[3,5]), padding='same'))\n",
    "    \n",
    "        Regressor.add(keras.layers.ReLU())\n",
    "        Regressor.add(keras.layers.MaxPooling3D(pool_size=(2,2,2),padding='same'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    " \n",
    "    Regressor.add(keras.layers.Conv3D(\n",
    "        filters= hp.Int('ConvFiltersInputLayer', min_value = 16, max_value=256,step=32),\n",
    "        kernel_size=hp.Choice('Conv2Kernel', values=[3,5]), padding='same',input_shape =(XPix, YPix,ZPix, 1)))\n",
    "        \n",
    " \n",
    "    \n",
    "    Regressor.add(keras.layers.ReLU()) \n",
    "    \n",
    "   \n",
    "    Regressor.add(keras.layers. GlobalAveragePooling3D())\n",
    "    \n",
    "    Regressor.add(keras.layers.Dense(1, activation='linear')) \n",
    "    \n",
    "    \n",
    "    Regressor.compile(loss=\"mean_absolute_error\", optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('LearningRate',[1e-2, 1e-3, 1e-4])))\n",
    "    return Regressor\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = EarlyStopping(monitor='val_loss', mode='min', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperband using keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuner = Hyperband(ModelCreation, objective= 'val_loss', max_epochs =epochs, executions_per_trial =1, seed=seed, directory=os.path.normpath('../3DFixed/NewArchitecture/codeOutputs/Permeability/TransportProp'), project_name='HyperUnRotValWholeDataManualSplit3DNewArchitectureFixedImages')\n",
    "\n",
    "Tuner.search(aaaiTrainImages, afTrainPermeability , verbose=2, validation_data= (aaaiValidationImages, afValidationPermeability ), epochs=epochs, callbacks=[EarlyStop])\n",
    "\n",
    "Tuner.search_space_summary()\n",
    "\n",
    "Model = Tuner.get_best_models(1)[0]\n",
    "\n",
    "print(Model.summary())\n",
    "\n",
    "Tuner.results_summary()\n",
    "\n",
    "print(Tuner.get_best_hyperparameters(1)[0].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the 1 channel added to the images before hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPix, YPix,ZPix = aaaiTrainImages.shape[1], aaaiTrainImages.shape[2],aaaiTrainImages.shape[3]\n",
    "aaaiTrainImages = aaaiTrainImages.reshape(-1,XPix,YPix,ZPix)\n",
    "aaaiValidationImages = aaaiValidationImages.reshape(-1,XPix,YPix,ZPix)\n",
    "aaaiTestImages = aaaiTestImages.reshape(-1,XPix,YPix,ZPix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Train Images shape without channel:', aaaiTrainImages.shape)\n",
    "print ('Validation Images shape without channel:', aaaiValidationImages.shape)\n",
    "print ('Test Images shape without channel:', aaaiTestImages.shape)\n",
    "print ('Train Permeability shape:', afTrainPermeability .shape)\n",
    "print ('Validation Permeability shape:', afValidationPermeability .shape)\n",
    "print ('Test Permeability shape:', afTestPermeability .shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation: We rotate train images by three angles of 90, 180, and 270 degress. \n",
    "These rotated images together with the original images will be used for training. Next these images are also flipped horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaiTrainImagesRot90 = np.rot90(aaaiTrainImages, axes=(-2,-1))\n",
    "print(aaaiTrainImagesRot90.shape)\n",
    "afTrainPermeability90 = np.copy(afTrainPermeability )\n",
    "print(afTrainPermeability90.shape)\n",
    "\n",
    "aaaiTrainImagesRot180 = np.rot90(aaaiTrainImagesRot90, axes=(-2,-1))\n",
    "print(aaaiTrainImagesRot180.shape)\n",
    "afTrainPermeability180 = np.copy(afTrainPermeability )\n",
    "print(afTrainPermeability180.shape)\n",
    "\n",
    "aaaiTrainImagesRot270 = np.rot90(aaaiTrainImagesRot180, axes=(-2,-1))\n",
    "print(aaaiTrainImagesRot270.shape)\n",
    "afTrainPermeability270 = np.copy(afTrainPermeability )\n",
    "print(afTrainPermeability270.shape)\n",
    "\n",
    "\n",
    "aaaiTrainImagesHorFlip = np.fliplr(aaaiTrainImages)\n",
    "afTrainPermeabilityHorFlip = np.copy(afTrainPermeability )\n",
    "print(aaaiTrainImagesHorFlip.shape)\n",
    "print(afTrainPermeabilityHorFlip.shape)\n",
    "\n",
    "\n",
    "aaaiTrainImagesHorFlip90 = np.fliplr(aaaiTrainImagesRot90)\n",
    "afTrainPermeabilityHorFlip90 = np.copy(afTrainPermeability )\n",
    "print(aaaiTrainImagesHorFlip90.shape)\n",
    "print(afTrainPermeabilityHorFlip90.shape)\n",
    "\n",
    "\n",
    "\n",
    "aaaiTrainImagesHorFlip180 = np.fliplr(aaaiTrainImagesRot180)\n",
    "afTrainPermeabilityHorFlip180 = np.copy(afTrainPermeability )\n",
    "print(aaaiTrainImagesHorFlip180.shape)\n",
    "print(afTrainPermeabilityHorFlip180.shape)\n",
    "\n",
    "aaaiTrainImagesHorFlip270 = np.fliplr(aaaiTrainImagesRot270)\n",
    "afTrainPermeabilityHorFlip270 = np.copy(afTrainPermeability )\n",
    "print(aaaiTrainImagesHorFlip270.shape)\n",
    "print(afTrainPermeabilityHorFlip270.shape)\n",
    "\n",
    "\n",
    "aaaiTrainImages = np.concatenate((aaaiTrainImages, aaaiTrainImagesRot90, aaaiTrainImagesRot180, aaaiTrainImagesRot270, aaaiTrainImagesHorFlip,aaaiTrainImagesHorFlip90,aaaiTrainImagesHorFlip180,aaaiTrainImagesHorFlip270), axis=0)\n",
    "afTrainPermeability  = np.concatenate((afTrainPermeability , afTrainPermeability90, afTrainPermeability180, afTrainPermeability270,afTrainPermeabilityHorFlip, afTrainPermeabilityHorFlip90,afTrainPermeabilityHorFlip180,afTrainPermeabilityHorFlip270), axis=0)\n",
    "\n",
    "np.save('../3DFixed/NewArchitecture/afTrain3DPermeabilityAugmentationConcatenateOldArchitectureFixedImagesAugmentation.npy',afTrainPermeability)\n",
    "np.savetxt('../3DFixed/NewArchitecture/afTrain3DPermeabilityAugmentationConcatenateOldArchitectureFixedImagesAugmentation.csv', afTrainPermeability )\n",
    "\n",
    "print(aaaiTrainImages.shape)\n",
    "print(afTrainPermeability .shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert each 19 x 19 x 19 image of the train, validation and test set into a matrix of size 19 x 19 x 19 1 which is fed into the network. 1 is for number of channels. We are working with grayscale images. Therefore we have 1 channel. RGB images have 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPix, YPix,ZPix = aaaiTrainImages.shape[1], aaaiTrainImages.shape[2],aaaiTrainImages.shape[3]\n",
    "aaaiTrainImages = aaaiTrainImages.reshape(-1,XPix,YPix,ZPix,1)\n",
    "aaaiValidationImages = aaaiValidationImages.reshape(-1,XPix,YPix,ZPix,1)\n",
    "aaaiTestImages = aaaiTestImages.reshape(-1,XPix,YPix,ZPix,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Train Images shape with channel:', aaaiTrainImages.shape)\n",
    "print ('Validation Images shape with channel:', aaaiValidationImages.shape)\n",
    "print ('Test Images shape with channel:', aaaiTestImages.shape)\n",
    "print ('Train Permeability shape:', afTrainPermeability .shape)\n",
    "print ('Validation Permeability shape:', afValidationPermeability .shape)\n",
    "print ('Test Permeability shape:', afTestPermeability .shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best returned model will train for more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 300\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', mode='min', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"../CheckPointTest/ThreeDNewArchitectureFixedAugmentation/\"\n",
    "\n",
    "ckpt_pathname = experiment + \"/cp-{epoch:04d}.ckpt\"\n",
    "csv_filename = experiment + \"/metricsThreeDNewArchitectureFixedAugmentation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback that saves the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_pathname, verbose=1)\n",
    "metrics_callback = tf.keras.callbacks.CSVLogger(csv_filename, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRegressor = Model.fit(aaaiTrainImages, afTrainPermeability, validation_data = (aaaiValidationImages, afValidationPermeability), epochs=Epochs, callbacks =[EarlyStop, cp_callback,metrics_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the specified checkpoint you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model = keras.models.load_model(experiment + \"cp-0005.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits the model after loading the ckechpoints an initial epoch you want to start with (eg:stopped after epoch 10, but initial epoch at 10, because it starts couting from 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BestRegressor1 = Model.fit(aaaiTrainImages, afTrainPermeability , validation_data = (aaaiValidationImages, afValidationPermeability), epochs=Epochs, initial_epoch=5, callbacks =[EarlyStop, cp_callback,metrics_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "print('Training took: ',(t1 - t0)/60,'minutes')\n",
    "\n",
    "\n",
    "\n",
    "TestLoss  = Model.evaluate(aaaiTestImages, afTestPermeability, verbose=2)\n",
    "print('Test loss:', TestLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the improvement in loss function for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(BestRegressor.history['loss'], color ='b')\n",
    "plt.plot(BestRegressor.history['val_loss'], color = 'r')\n",
    "#plt.title('model loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig('3DCNNModelManualSplitNewArchFixedAugmentation2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and save the model and predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "afPredictedPermeability  = Model.predict(aaaiTestImages)\n",
    "np.savetxt('../codeOutputs/Permeability/TransportProp/PredictedPermeability300EpochsMAEWholeDataManualSplit3DNewArchitectureFixedAugmentation.csv', afPredictedPermeability)\n",
    "save_model(Model, filepath= '../Models/PermeabilityEstimation/CNNModelForPermeabilityEstimation300EpochsMAEWholeDataManualSplit3DNewArchitectureFixedAugmentation', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
